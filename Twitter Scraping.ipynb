{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91505bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting twitterscraper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile twitterscraper.py\n",
    "\n",
    "# Import relevant libraries\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import streamlit as st\n",
    "from datetime import date\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# List of scraped tweets based on the user input\n",
    "def Scrapingdata(Hashtag,start_date,End_date,tweets_count):\n",
    "      tweets_list=[]\n",
    "      for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{Hashtag} since:{start_date} until:{End_date}', top = True).get_items()):\n",
    "           if i>=tweets_count:\n",
    "               break\n",
    "           tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.url, tweet.retweetCount, tweet.source, tweet.likeCount,tweet.replyCount,tweet.lang])\n",
    "      return(tweets_list)\n",
    "\n",
    "# Menu section of the appy\n",
    "st.set_page_config(page_title=\"Twitter Scraping\", page_icon=':bird:', layout=\"centered\", initial_sidebar_state=\"expanded\")\n",
    "menu=[\"Home\",\"About\",\"Search\",\"Display\",\"Download\"]\n",
    "choice=st.sidebar.selectbox(\"menu\",menu)\n",
    "\n",
    "# Home page of the app\n",
    "if choice==\"Home\": \n",
    "    st.title(':black[_Twitter Scraping App_]')\n",
    "    st.markdown(\"_***This app was created with the Streamlit app framework. The app scrapes Twitter data based on user-inputted hashtags/keywords and date range. Additionally, it allows users to upload tweets data to MongoDB and download it as a CSV or JSON file.***_\")\n",
    "    img=Image.open(\"elonmusk.webp\")\n",
    "    st.image(img)\n",
    "\n",
    "# About page of the app\n",
    "elif choice==\"About\":\n",
    "    with st.expander(\"**Twitter Scraping**\"):\n",
    "        st.write(\"Twitter Scraper will scrap data from public twitter profiles. It can collect data such as **date, id, url, tweet content, reply count, retweet, count, language, like count, followers etc** from tweets\")\n",
    "    with st.expander(\"**Snscrape**\"):\n",
    "        st.write(\"Snscrape is a scraper for social networking services (SNS). It scrapes things like user profiles, hashtags, or searches and returns the discovered items, e.g. the relevant posts.\")\n",
    "    with st.expander(\"**Mongodb**\"):\n",
    "        st.write(\"MongoDB is an open-source document-oriented database that is designed to store a large scale of data and also allows you to work with that data very efficiently.\")\n",
    "    with st.expander(\"**Streamlit**\"):\n",
    "        st.write(\"Streamlit is an open source app framework in python language. It helps us create beautiful web-apps for data science and machine learning in a little time. It is compatible with major python libraries such as scikit-learn, keras, pytorch, latex, numpy, pandas, matplotlib, etc.\")\n",
    "        st.balloons()\n",
    "\n",
    "# Search and Scrape tweets\n",
    "elif choice==\"Search\":\n",
    "    Hashtag=st.text_input(\"Enter Hashtag or Keyword\")\n",
    "    start_date=st.date_input(\"Enter starting date:(YYYY-MM-DD)\")\n",
    "    End_date=st.date_input(\"Enter end date:(YYYY-MM-DD)\")\n",
    "    tweets_count=st.number_input(\"Enter Tweet count\",min_value=1,max_value=1500,step=2)\n",
    "    if Hashtag:\n",
    "        submit=st.checkbox(\"**Scrape Tweets**\")\n",
    "        if submit:\n",
    "\n",
    "             data=Scrapingdata(Hashtag,start_date,End_date,tweets_count)\n",
    "             st.success(\"Data scraped successfully!\")\n",
    "             st.balloons()\n",
    "             def data_frame(data):\n",
    "                    return pd.DataFrame(data,columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"url\",\"retweetCount\",\"source\",\"like_count\",\"replycount\",\"lan\"])\n",
    "             df=data_frame(data)\n",
    "            \n",
    "# Connect to MongoDB database\n",
    "             client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "             db = client.Twitter\n",
    "             records=db.scrapping\n",
    "             today=str(date.today())\n",
    "             scr_data={\"Scraped_word\":Hashtag,\"Scraped_date\":today,\"Scraped_data\":df.to_dict(\"list\")}\n",
    "             records.delete_many({})\n",
    "             records.insert_one(scr_data)\n",
    "             st.success(\"Uploaded to MongoDB successfully!\")\n",
    "             st.balloons()\n",
    "\n",
    "    else:\n",
    "         st.checkbox(\"Scrape Tweet Data\",disabled=True)\n",
    "\n",
    "# Display scraped data\n",
    "elif choice==\"Display\":\n",
    "    Hashtag=st.sidebar.text_input(\"Enter Hashtag or Keyword\")\n",
    "    start_date=st.sidebar.date_input(\"Enter starting date:(YYYY-MM-DD)\")\n",
    "    End_date=st.sidebar.date_input(\"Enter end date:(YYYY-MM-DD)\")\n",
    "    tweets_count=st.sidebar.number_input(\"Enter Tweet count\",min_value=1,max_value=1500,step=2)\n",
    "    list_tweet=Scrapingdata(Hashtag,start_date,End_date,tweets_count)\n",
    "    def data_frame(data):\n",
    "         return(pd.DataFrame(data,columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"url\",\"retweetCount\",\"source\",\"like_count\",\"replycount\",\"lan\"]))\n",
    "    df=data_frame(list_tweet)\n",
    "    submit=st.checkbox(\"View Dataframe\") \n",
    "    if submit:\n",
    "          st.success(\"Dataframe\")\n",
    "          st.write(df) \n",
    "\n",
    "# Download scraped data as CSV or JSON file\n",
    "elif choice==\"Download\":\n",
    "    Hashtag=st.sidebar.text_input(\"Enter Hashtag or Keyword\")\n",
    "    start_date=st.sidebar.date_input(\"Enter starting date:(YYYY-MM-DD)\")\n",
    "    End_date=st.sidebar.date_input(\"Enter end date:(YYYY-MM-DD)\")\n",
    "    tweets_count=st.sidebar.number_input(\"Enter Tweet count\",min_value=1,max_value=1500,step=2)\n",
    "    tweetlist=Scrapingdata(Hashtag,start_date,End_date,tweets_count)\n",
    "    def data_frame(data):\n",
    "         return(pd.DataFrame(data,columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"url\",\"retweetCount\",\"source\",\"like_count\",\"replycount\",\"lan\"]))\n",
    "    \n",
    "    def convert_csv(df_input_csv):\n",
    "          return df_input_csv.to_csv().encode(\"utf-8\")\n",
    "\n",
    "    def convert_json(j):\n",
    "          return j.to_json(orient=\"index\")\n",
    "\n",
    "    df=data_frame(tweetlist)\n",
    "    csv=convert_csv(df)\n",
    "    json = convert_json(df)\n",
    "    st.download_button(label=\"Download CSV\",data=csv,file_name=\"file.csv\",mime=\"text/csv\") \n",
    "    st.download_button(label=\"Download JSON\",data=json,file_name=\"file.json\",mime=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec11d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
